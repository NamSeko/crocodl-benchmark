{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52a270de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-30 16:50:03.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mRoMa.romatch.models.model_zoo.roma_models\u001b[0m:\u001b[36mroma_model\u001b[0m:\u001b[36m61\u001b[0m - \u001b[1mUsing coarse resolution (560, 560), and upsample res (216, 288)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from RoMa.romatch.utils.utils import tensor_to_pil\n",
    "\n",
    "from RoMa.romatch import roma_outdoor\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--im_A_path\", default=\"RoMa/assets/sacre_coeur_A.jpg\", type=str)\n",
    "parser.add_argument(\"--im_B_path\", default=\"RoMa/assets/sacre_coeur_B.jpg\", type=str)\n",
    "parser.add_argument(\"--save_path\", default=\"RoMa/demo/roma_warp_sacre_coeur.jpg\", type=str)\n",
    "\n",
    "args, _ = parser.parse_known_args()\n",
    "im1_path = args.im_A_path\n",
    "im2_path = args.im_B_path\n",
    "save_path = args.save_path\n",
    "\n",
    "# Create model\n",
    "roma_model = roma_outdoor(device=device, coarse_res=560, upsample_res=(216, 288))\n",
    "\n",
    "H, W = roma_model.get_output_resolution()\n",
    "\n",
    "im1 = Image.open(im1_path).resize((W, H))\n",
    "im2 = Image.open(im2_path).resize((W, H))\n",
    "\n",
    "# Match\n",
    "warp, certainty = roma_model.match(im1_path, im2_path, device=device)\n",
    "# Sampling not needed, but can be done with model.sample(warp, certainty)\n",
    "x1 = (torch.tensor(np.array(im1)) / 255).to(device).permute(2, 0, 1)\n",
    "x2 = (torch.tensor(np.array(im2)) / 255).to(device).permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cbf337f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 2 to 1\n",
      "tensor([[[[-0.6894, -0.2032],\n",
      "          [-0.6867, -0.2059],\n",
      "          [-0.6875, -0.2115],\n",
      "          ...,\n",
      "          [ 0.9765, -0.4433],\n",
      "          [ 0.9814, -0.4405],\n",
      "          [ 0.9841, -0.4375]],\n",
      "\n",
      "         [[-0.6905, -0.2010],\n",
      "          [-0.6881, -0.2033],\n",
      "          [-0.6876, -0.2071],\n",
      "          ...,\n",
      "          [ 0.9772, -0.4346],\n",
      "          [ 0.9808, -0.4320],\n",
      "          [ 0.9829, -0.4317]],\n",
      "\n",
      "         [[-0.6904, -0.1982],\n",
      "          [-0.6884, -0.2011],\n",
      "          [-0.6886, -0.2051],\n",
      "          ...,\n",
      "          [ 0.9787, -0.4246],\n",
      "          [ 0.9822, -0.4226],\n",
      "          [ 0.9861, -0.4222]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.4797,  0.8542],\n",
      "          [-0.4758,  0.8540],\n",
      "          [-0.4713,  0.8530],\n",
      "          ...,\n",
      "          [ 0.7370,  0.8057],\n",
      "          [ 0.7418,  0.8062],\n",
      "          [ 0.7463,  0.8061]],\n",
      "\n",
      "         [[-0.4790,  0.8587],\n",
      "          [-0.4747,  0.8581],\n",
      "          [-0.4701,  0.8580],\n",
      "          ...,\n",
      "          [ 0.7364,  0.8098],\n",
      "          [ 0.7404,  0.8099],\n",
      "          [ 0.7436,  0.8110]],\n",
      "\n",
      "         [[-0.4795,  0.8633],\n",
      "          [-0.4732,  0.8627],\n",
      "          [-0.4694,  0.8630],\n",
      "          ...,\n",
      "          [ 0.7369,  0.8151],\n",
      "          [ 0.7411,  0.8139],\n",
      "          [ 0.7433,  0.8153]]]])\n",
      "Image 1 to 2\n",
      "tensor([[[[-0.5788, -0.9132],\n",
      "          [-0.5719, -0.9171],\n",
      "          [-0.5635, -0.9249],\n",
      "          ...,\n",
      "          [ 0.9868, -1.0000],\n",
      "          [ 0.9873, -1.0000],\n",
      "          [ 0.9881, -1.0000]],\n",
      "\n",
      "         [[-0.5744, -0.9100],\n",
      "          [-0.5679, -0.9138],\n",
      "          [-0.5591, -0.9202],\n",
      "          ...,\n",
      "          [ 0.9869, -1.0000],\n",
      "          [ 0.9867, -1.0000],\n",
      "          [ 0.9875, -1.0000]],\n",
      "\n",
      "         [[-0.5630, -0.9048],\n",
      "          [-0.5581, -0.9093],\n",
      "          [-0.5511, -0.9175],\n",
      "          ...,\n",
      "          [ 0.9878, -1.0000],\n",
      "          [ 0.9885, -1.0000],\n",
      "          [ 0.9912, -1.0000]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.8463,  1.0000],\n",
      "          [-0.8453,  1.0000],\n",
      "          [-0.8472,  1.0000],\n",
      "          ...,\n",
      "          [ 0.9224,  0.9894],\n",
      "          [ 0.9250,  0.9880],\n",
      "          [ 0.9300,  0.9875]],\n",
      "\n",
      "         [[-0.8403,  1.0000],\n",
      "          [-0.8391,  1.0000],\n",
      "          [-0.8408,  1.0000],\n",
      "          ...,\n",
      "          [ 0.9217,  0.9962],\n",
      "          [ 0.9231,  0.9935],\n",
      "          [ 0.9275,  0.9941]],\n",
      "\n",
      "         [[-0.8374,  1.0000],\n",
      "          [-0.8345,  1.0000],\n",
      "          [-0.8373,  1.0000],\n",
      "          ...,\n",
      "          [ 0.9229,  1.0000],\n",
      "          [ 0.9246,  0.9991],\n",
      "          [ 0.9261,  0.9993]]]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Image 2 to 1\")\n",
    "print(warp[:,:,:W,2:])\n",
    "print(\"Image 1 to 2\")\n",
    "print(warp[:,:,W:,:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a15b1bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of grid_im2: torch.Size([1, 216, 288, 2])\n",
      "Shape of grid_im1: torch.Size([1, 216, 288, 2])\n",
      "Shape of x2[None]: torch.Size([1, 3, 216, 288])\n",
      "Shape of x1[None]: torch.Size([1, 3, 216, 288])\n",
      "Spahe of warp: torch.Size([1, 216, 576, 4])\n",
      "Shape of warp_im: torch.Size([3, 216, 576])\n",
      "Shape of white_im: torch.Size([216, 576])\n",
      "Shape of certainty: torch.Size([1, 216, 576])\n"
     ]
    }
   ],
   "source": [
    "grid_im2 = warp[:, :, :W, 2:]\n",
    "grid_im1 = warp[:, :, W:, :2]\n",
    "print(f\"Shape of grid_im2: {grid_im2.shape}\")\n",
    "print(f\"Shape of grid_im1: {grid_im1.shape}\")\n",
    "print(f\"Shape of x2[None]: {x2[None].shape}\")\n",
    "print(f\"Shape of x1[None]: {x1[None].shape}\")\n",
    "print(f\"Spahe of warp: {warp.shape}\")\n",
    "\n",
    "im2_transfer_rgb = F.grid_sample(\n",
    "x2[None], grid_im2, mode=\"bilinear\", align_corners=False\n",
    ")[0]\n",
    "im1_transfer_rgb = F.grid_sample(\n",
    "x1[None], grid_im1, mode=\"bilinear\", align_corners=False\n",
    ")[0]\n",
    "warp_im = torch.cat((im2_transfer_rgb,im1_transfer_rgb),dim=2)\n",
    "white_im = torch.ones((H,2*W),device=device)\n",
    "print(f\"Shape of warp_im: {warp_im.shape}\")\n",
    "print(f\"Shape of white_im: {white_im.shape}\")\n",
    "print(f\"Shape of certainty: {certainty.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5dcd396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_im = certainty * warp_im + (1 - certainty) * white_im\n",
    "tensor_to_pil(vis_im, unnormalize=False).save(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "croco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
